{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "37150807",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T11:01:16.107241Z",
     "iopub.status.busy": "2025-04-07T11:01:16.106931Z",
     "iopub.status.idle": "2025-04-07T11:01:23.167880Z",
     "shell.execute_reply": "2025-04-07T11:01:23.167089Z"
    },
    "papermill": {
     "duration": 7.065468,
     "end_time": "2025-04-07T11:01:23.169370",
     "exception": false,
     "start_time": "2025-04-07T11:01:16.103902",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our data directory is /kaggle/input/chest-xray-pneumonia/chest_xray\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# data_dir = os.path.join(os.getcwd(), \"drive\", \"MyDrive\", \"pneumonia\")\n",
    "data_dir = os.path.join(\"/kaggle/input/chest-xray-pneumonia/chest_xray\")\n",
    "print(f\"Our data directory is {data_dir}\")\n",
    "\n",
    "train_dir = os.path.join(data_dir, \"train\")\n",
    "test_dir = os.path.join(data_dir, \"test\")\n",
    "val_dir = os.path.join(data_dir, \"val\")\n",
    "\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7d520140",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T11:01:23.174011Z",
     "iopub.status.busy": "2025-04-07T11:01:23.173689Z",
     "iopub.status.idle": "2025-04-07T11:01:26.590958Z",
     "shell.execute_reply": "2025-04-07T11:01:26.590244Z"
    },
    "papermill": {
     "duration": 3.420941,
     "end_time": "2025-04-07T11:01:26.592497",
     "exception": false,
     "start_time": "2025-04-07T11:01:23.171556",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "traindataset = ImageFolder(root=train_dir, transform=transform)\n",
    "valdataset = ImageFolder(root=val_dir, transform=transform)\n",
    "train_loader = DataLoader(traindataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(valdataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a204f4ac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T11:01:26.597723Z",
     "iopub.status.busy": "2025-04-07T11:01:26.597493Z",
     "iopub.status.idle": "2025-04-07T11:01:26.608412Z",
     "shell.execute_reply": "2025-04-07T11:01:26.607848Z"
    },
    "papermill": {
     "duration": 0.014991,
     "end_time": "2025-04-07T11:01:26.609615",
     "exception": false,
     "start_time": "2025-04-07T11:01:26.594624",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as f\n",
    "\n",
    "class Basicblock(nn.Module):\n",
    "    expansion=1\n",
    "\n",
    "    def __init__(self,in_channels,out_channels,stride=1,downsample=None):\n",
    "        super(Basicblock,self).__init__()\n",
    "        self.conv1=nn.Conv2d(in_channels,out_channels,kernel_size=3,stride=stride,padding=1,bias=False)\n",
    "        self.bn1=nn.BatchNorm2d(out_channels)\n",
    "        self.conv2=nn.Conv2d(out_channels,out_channels,kernel_size=3,stride=1,padding=1,bias=False)\n",
    "        self.bn2=nn.BatchNorm2d(out_channels)\n",
    "        self.downsample= downsample\n",
    "        self.relu=nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self,x):\n",
    "        identity=x\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "        out=self.conv1(x)\n",
    "        out=self.bn1(out)\n",
    "        out=f.relu(out)\n",
    "        out=self.conv2(out)\n",
    "        out=self.bn2(out)\n",
    "        out+=identity\n",
    "        out=f.relu(out)\n",
    "        return out\n",
    "class Resnet34(nn.Module):\n",
    "    def __init__(self,num_classes=1):\n",
    "        super(Resnet34,self).__init__()\n",
    "        self.in_channels=64\n",
    "        self.conv1=nn.Conv2d(3,64,kernel_size=7,stride=2,padding=3,bias=False)\n",
    "        self.bn1=nn.BatchNorm2d(64)\n",
    "        self.relu=nn.ReLU(inplace=True)\n",
    "        self.maxpool=nn.MaxPool2d(kernel_size=3,stride=2,padding=1)\n",
    "\n",
    "        self.layer1=self.makelayer(64,3)\n",
    "        self.layer2=self.makelayer(128,4,stride=2)\n",
    "        self.layer3=self.makelayer(256,6,stride=2)\n",
    "        self.layer4=self.makelayer(512,3,stride=2)\n",
    "        self.avgpool=nn.AdaptiveAvgPool2d((1,1))\n",
    "        self.fc=nn.Linear(512,num_classes)\n",
    "    def makelayer(self,out_channels,blocks,stride=1):\n",
    "        downsample=None\n",
    "        if stride!=1 or self.in_channels!=out_channels:\n",
    "            downsample=nn.Sequential(nn.Conv2d(self.in_channels,out_channels,kernel_size=1,stride=stride,bias=False),\n",
    "                                    nn.BatchNorm2d(out_channels))\n",
    "        layers=[Basicblock(self.in_channels,out_channels,stride,downsample)]\n",
    "        self.in_channels=out_channels\n",
    "        for i in range(1,blocks):\n",
    "            layers.append(Basicblock(self.in_channels,out_channels))\n",
    "        return nn.Sequential(*layers)\n",
    "    def forward(self, x):\n",
    "        x=self.conv1(x)\n",
    "        x=self.bn1(x)\n",
    "        x=self.relu(x)\n",
    "        x=self.maxpool(x)\n",
    "\n",
    "        x=self.layer1(x)\n",
    "        x=self.layer2(x)\n",
    "        x=self.layer3(x)\n",
    "        x=self.layer4(x)\n",
    "\n",
    "        x=self.avgpool(x)\n",
    "        x=torch.flatten(x,1)\n",
    "        x=self.fc(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a91f7d9b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T11:01:26.613453Z",
     "iopub.status.busy": "2025-04-07T11:01:26.613249Z",
     "iopub.status.idle": "2025-04-07T11:16:34.016116Z",
     "shell.execute_reply": "2025-04-07T11:16:34.015201Z"
    },
    "papermill": {
     "duration": 907.407921,
     "end_time": "2025-04-07T11:16:34.019123",
     "exception": false,
     "start_time": "2025-04-07T11:01:26.611202",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10] | Loss: 0.1759 | Accuracy: 0.9346\n",
      "Epoch [2/10] | Loss: 0.0872 | Accuracy: 0.9670\n",
      "Epoch [3/10] | Loss: 0.0639 | Accuracy: 0.9772\n",
      "Epoch [4/10] | Loss: 0.0552 | Accuracy: 0.9797\n",
      "Epoch [5/10] | Loss: 0.0367 | Accuracy: 0.9870\n",
      "Epoch [6/10] | Loss: 0.0417 | Accuracy: 0.9843\n",
      "Epoch [7/10] | Loss: 0.0236 | Accuracy: 0.9929\n",
      "Epoch [8/10] | Loss: 0.0115 | Accuracy: 0.9964\n",
      "Epoch [9/10] | Loss: 0.0203 | Accuracy: 0.9921\n",
      "Epoch [10/10] | Loss: 0.0215 | Accuracy: 0.9919\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "model=Resnet34()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "criterion=nn.BCEWithLogitsLoss()\n",
    "optimizer=optim.Adam(model.parameters(),lr=1e-4)\n",
    "\n",
    "num_epochs=10\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    runningloss=0\n",
    "    correct=0\n",
    "    total=0\n",
    "\n",
    "    for inputs, targets in train_loader:\n",
    "        inputs=inputs.to(device)\n",
    "        targets=targets.to(device).float().unsqueeze(1)\n",
    "        outputs=model(inputs)\n",
    "        loss=criterion(outputs,targets)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        runningloss+=loss.item()\n",
    "\n",
    "        pred=torch.sigmoid(outputs)>0.5\n",
    "        correct+=(pred==targets.bool()).sum().item()\n",
    "        total+=targets.size(0)\n",
    "    epoch_loss=runningloss/len(train_loader)\n",
    "    epoch_acc=correct/total\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}] | Loss: {epoch_loss:.4f} | Accuracy: {epoch_acc:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 17810,
     "sourceId": 23812,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 921.801893,
   "end_time": "2025-04-07T11:16:35.441856",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-04-07T11:01:13.639963",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
