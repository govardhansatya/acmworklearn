{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "37150807",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T11:01:16.107241Z",
     "iopub.status.busy": "2025-04-07T11:01:16.106931Z",
     "iopub.status.idle": "2025-04-07T11:01:23.167880Z",
     "shell.execute_reply": "2025-04-07T11:01:23.167089Z"
    },
    "papermill": {
     "duration": 7.065468,
     "end_time": "2025-04-07T11:01:23.169370",
     "exception": false,
     "start_time": "2025-04-07T11:01:16.103902",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our data directory is /kaggle/input/chest-xray-pneumonia/chest_xray\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 10\u001b[0m\n\u001b[0;32m      7\u001b[0m test_dir \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(data_dir, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      8\u001b[0m val_dir \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(data_dir, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorchvision\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatasets\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ImageFolder\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorchvision\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m transforms\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DataLoader\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torchvision\\__init__.py:5\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mwarnings\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmodulefinder\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Module\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Don't re-order these, we need to load the _C extension (done when importing\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# .extensions) before entering _meta_registrations.\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mextension\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _HAS_OPS  \u001b[38;5;66;03m# usort:skip\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\__init__.py:2151\u001b[0m\n\u001b[0;32m   2135\u001b[0m \u001b[38;5;66;03m################################################################################\u001b[39;00m\n\u001b[0;32m   2136\u001b[0m \u001b[38;5;66;03m# Import most common subpackages\u001b[39;00m\n\u001b[0;32m   2137\u001b[0m \u001b[38;5;66;03m################################################################################\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2142\u001b[0m \n\u001b[0;32m   2143\u001b[0m \u001b[38;5;66;03m# needs to be before import torch.nn as nn to avoid circular dependencies\u001b[39;00m\n\u001b[0;32m   2144\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograd\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (  \u001b[38;5;66;03m# usort: skip\u001b[39;00m\n\u001b[0;32m   2145\u001b[0m     enable_grad \u001b[38;5;28;01mas\u001b[39;00m enable_grad,\n\u001b[0;32m   2146\u001b[0m     inference_mode \u001b[38;5;28;01mas\u001b[39;00m inference_mode,\n\u001b[0;32m   2147\u001b[0m     no_grad \u001b[38;5;28;01mas\u001b[39;00m no_grad,\n\u001b[0;32m   2148\u001b[0m     set_grad_enabled \u001b[38;5;28;01mas\u001b[39;00m set_grad_enabled,\n\u001b[0;32m   2149\u001b[0m )\n\u001b[1;32m-> 2151\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m   2152\u001b[0m     __config__ \u001b[38;5;28;01mas\u001b[39;00m __config__,\n\u001b[0;32m   2153\u001b[0m     __future__ \u001b[38;5;28;01mas\u001b[39;00m __future__,\n\u001b[0;32m   2154\u001b[0m     _awaits \u001b[38;5;28;01mas\u001b[39;00m _awaits,\n\u001b[0;32m   2155\u001b[0m     accelerator \u001b[38;5;28;01mas\u001b[39;00m accelerator,\n\u001b[0;32m   2156\u001b[0m     autograd \u001b[38;5;28;01mas\u001b[39;00m autograd,\n\u001b[0;32m   2157\u001b[0m     backends \u001b[38;5;28;01mas\u001b[39;00m backends,\n\u001b[0;32m   2158\u001b[0m     cpu \u001b[38;5;28;01mas\u001b[39;00m cpu,\n\u001b[0;32m   2159\u001b[0m     cuda \u001b[38;5;28;01mas\u001b[39;00m cuda,\n\u001b[0;32m   2160\u001b[0m     distributed \u001b[38;5;28;01mas\u001b[39;00m distributed,\n\u001b[0;32m   2161\u001b[0m     distributions \u001b[38;5;28;01mas\u001b[39;00m distributions,\n\u001b[0;32m   2162\u001b[0m     fft \u001b[38;5;28;01mas\u001b[39;00m fft,\n\u001b[0;32m   2163\u001b[0m     futures \u001b[38;5;28;01mas\u001b[39;00m futures,\n\u001b[0;32m   2164\u001b[0m     hub \u001b[38;5;28;01mas\u001b[39;00m hub,\n\u001b[0;32m   2165\u001b[0m     jit \u001b[38;5;28;01mas\u001b[39;00m jit,\n\u001b[0;32m   2166\u001b[0m     linalg \u001b[38;5;28;01mas\u001b[39;00m linalg,\n\u001b[0;32m   2167\u001b[0m     mps \u001b[38;5;28;01mas\u001b[39;00m mps,\n\u001b[0;32m   2168\u001b[0m     mtia \u001b[38;5;28;01mas\u001b[39;00m mtia,\n\u001b[0;32m   2169\u001b[0m     multiprocessing \u001b[38;5;28;01mas\u001b[39;00m multiprocessing,\n\u001b[0;32m   2170\u001b[0m     nested \u001b[38;5;28;01mas\u001b[39;00m nested,\n\u001b[0;32m   2171\u001b[0m     nn \u001b[38;5;28;01mas\u001b[39;00m nn,\n\u001b[0;32m   2172\u001b[0m     optim \u001b[38;5;28;01mas\u001b[39;00m optim,\n\u001b[0;32m   2173\u001b[0m     overrides \u001b[38;5;28;01mas\u001b[39;00m overrides,\n\u001b[0;32m   2174\u001b[0m     profiler \u001b[38;5;28;01mas\u001b[39;00m profiler,\n\u001b[0;32m   2175\u001b[0m     sparse \u001b[38;5;28;01mas\u001b[39;00m sparse,\n\u001b[0;32m   2176\u001b[0m     special \u001b[38;5;28;01mas\u001b[39;00m special,\n\u001b[0;32m   2177\u001b[0m     testing \u001b[38;5;28;01mas\u001b[39;00m testing,\n\u001b[0;32m   2178\u001b[0m     types \u001b[38;5;28;01mas\u001b[39;00m types,\n\u001b[0;32m   2179\u001b[0m     utils \u001b[38;5;28;01mas\u001b[39;00m utils,\n\u001b[0;32m   2180\u001b[0m     xpu \u001b[38;5;28;01mas\u001b[39;00m xpu,\n\u001b[0;32m   2181\u001b[0m )\n\u001b[0;32m   2182\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msignal\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m windows \u001b[38;5;28;01mas\u001b[39;00m windows\n\u001b[0;32m   2185\u001b[0m \u001b[38;5;66;03m# Quantized, sparse, AO, etc. should be last to get imported, as nothing\u001b[39;00m\n\u001b[0;32m   2186\u001b[0m \u001b[38;5;66;03m# is expected to depend on them.\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\hub.py:64\u001b[0m\n\u001b[0;32m     60\u001b[0m         sys\u001b[38;5;241m.\u001b[39mstderr\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 64\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtqdm\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tqdm  \u001b[38;5;66;03m# If tqdm is installed use it, otherwise use the fake wrapper\u001b[39;00m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[0;32m     66\u001b[0m     tqdm \u001b[38;5;241m=\u001b[39m _Faketqdm\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\tqdm\\__init__.py:3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_monitor\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TMonitor, TqdmSynchronisationWarning\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_tqdm_pandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tqdm_pandas\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcli\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m main  \u001b[38;5;66;03m# TODO: remove in v5.0.0\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgui\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tqdm \u001b[38;5;28;01mas\u001b[39;00m tqdm_gui  \u001b[38;5;66;03m# TODO: remove in v5.0.0\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgui\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m trange \u001b[38;5;28;01mas\u001b[39;00m tgrange  \u001b[38;5;66;03m# TODO: remove in v5.0.0\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\tqdm\\cli.py:10\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mast\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m literal_eval \u001b[38;5;28;01mas\u001b[39;00m numeric\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtextwrap\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m indent\n\u001b[1;32m---> 10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstd\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TqdmKeyError, TqdmTypeError, tqdm\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mversion\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m __version__\n\u001b[0;32m     13\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmain\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1360\u001b[0m, in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1331\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:935\u001b[0m, in \u001b[0;36m_load_unlocked\u001b[1;34m(spec)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:995\u001b[0m, in \u001b[0;36mexec_module\u001b[1;34m(self, module)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:1091\u001b[0m, in \u001b[0;36mget_code\u001b[1;34m(self, fullname)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:1190\u001b[0m, in \u001b[0;36mget_data\u001b[1;34m(self, path)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "# data_dir = os.path.join(os.getcwd(), \"drive\", \"MyDrive\", \"pneumonia\")\n",
    "data_dir = os.path.join(\"/kaggle/input/chest-xray-pneumonia/chest_xray\")\n",
    "print(f\"Our data directory is {data_dir}\")\n",
    "\n",
    "train_dir = os.path.join(data_dir, \"train\")\n",
    "test_dir = os.path.join(data_dir, \"test\")\n",
    "val_dir = os.path.join(data_dir, \"val\")\n",
    "\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7d520140",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T11:01:23.174011Z",
     "iopub.status.busy": "2025-04-07T11:01:23.173689Z",
     "iopub.status.idle": "2025-04-07T11:01:26.590958Z",
     "shell.execute_reply": "2025-04-07T11:01:26.590244Z"
    },
    "papermill": {
     "duration": 3.420941,
     "end_time": "2025-04-07T11:01:26.592497",
     "exception": false,
     "start_time": "2025-04-07T11:01:23.171556",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "traindataset = ImageFolder(root=train_dir, transform=transform)\n",
    "valdataset = ImageFolder(root=val_dir, transform=transform)\n",
    "train_loader = DataLoader(traindataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(valdataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a204f4ac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T11:01:26.597723Z",
     "iopub.status.busy": "2025-04-07T11:01:26.597493Z",
     "iopub.status.idle": "2025-04-07T11:01:26.608412Z",
     "shell.execute_reply": "2025-04-07T11:01:26.607848Z"
    },
    "papermill": {
     "duration": 0.014991,
     "end_time": "2025-04-07T11:01:26.609615",
     "exception": false,
     "start_time": "2025-04-07T11:01:26.594624",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as f\n",
    "\n",
    "class Basicblock(nn.Module):\n",
    "    expansion=1\n",
    "\n",
    "    def __init__(self,in_channels,out_channels,stride=1,downsample=None):\n",
    "        super(Basicblock,self).__init__()\n",
    "        self.conv1=nn.Conv2d(in_channels,out_channels,kernel_size=3,stride=stride,padding=1,bias=False)\n",
    "        self.bn1=nn.BatchNorm2d(out_channels)\n",
    "        self.conv2=nn.Conv2d(out_channels,out_channels,kernel_size=3,stride=1,padding=1,bias=False)\n",
    "        self.bn2=nn.BatchNorm2d(out_channels)\n",
    "        self.downsample= downsample\n",
    "        self.relu=nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self,x):\n",
    "        identity=x\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "        out=self.conv1(x)\n",
    "        out=self.bn1(out)\n",
    "        out=f.relu(out)\n",
    "        out=self.conv2(out)\n",
    "        out=self.bn2(out)\n",
    "        out+=identity\n",
    "        out=f.relu(out)\n",
    "        return out\n",
    "class Resnet34(nn.Module):\n",
    "    def __init__(self,num_classes=1):\n",
    "        super(Resnet34,self).__init__()\n",
    "        self.in_channels=64\n",
    "        self.conv1=nn.Conv2d(3,64,kernel_size=7,stride=2,padding=3,bias=False)\n",
    "        self.bn1=nn.BatchNorm2d(64)\n",
    "        self.relu=nn.ReLU(inplace=True)\n",
    "        self.maxpool=nn.MaxPool2d(kernel_size=3,stride=2,padding=1)\n",
    "\n",
    "        self.layer1=self.makelayer(64,3)\n",
    "        self.layer2=self.makelayer(128,4,stride=2)\n",
    "        self.layer3=self.makelayer(256,6,stride=2)\n",
    "        self.layer4=self.makelayer(512,3,stride=2)\n",
    "        self.avgpool=nn.AdaptiveAvgPool2d((1,1))\n",
    "        self.fc=nn.Linear(512,num_classes)\n",
    "    def makelayer(self,out_channels,blocks,stride=1):\n",
    "        downsample=None\n",
    "        if stride!=1 or self.in_channels!=out_channels:\n",
    "            downsample=nn.Sequential(nn.Conv2d(self.in_channels,out_channels,kernel_size=1,stride=stride,bias=False),\n",
    "                                    nn.BatchNorm2d(out_channels))\n",
    "        layers=[Basicblock(self.in_channels,out_channels,stride,downsample)]\n",
    "        self.in_channels=out_channels\n",
    "        for i in range(1,blocks):\n",
    "            layers.append(Basicblock(self.in_channels,out_channels))\n",
    "        return nn.Sequential(*layers)\n",
    "    def forward(self, x):\n",
    "        x=self.conv1(x)\n",
    "        x=self.bn1(x)\n",
    "        x=self.relu(x)\n",
    "        x=self.maxpool(x)\n",
    "\n",
    "        x=self.layer1(x)\n",
    "        x=self.layer2(x)\n",
    "        x=self.layer3(x)\n",
    "        x=self.layer4(x)\n",
    "\n",
    "        x=self.avgpool(x)\n",
    "        x=torch.flatten(x,1)\n",
    "        x=self.fc(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a91f7d9b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T11:01:26.613453Z",
     "iopub.status.busy": "2025-04-07T11:01:26.613249Z",
     "iopub.status.idle": "2025-04-07T11:16:34.016116Z",
     "shell.execute_reply": "2025-04-07T11:16:34.015201Z"
    },
    "papermill": {
     "duration": 907.407921,
     "end_time": "2025-04-07T11:16:34.019123",
     "exception": false,
     "start_time": "2025-04-07T11:01:26.611202",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10] | Loss: 0.1759 | Accuracy: 0.9346\n",
      "Epoch [2/10] | Loss: 0.0872 | Accuracy: 0.9670\n",
      "Epoch [3/10] | Loss: 0.0639 | Accuracy: 0.9772\n",
      "Epoch [4/10] | Loss: 0.0552 | Accuracy: 0.9797\n",
      "Epoch [5/10] | Loss: 0.0367 | Accuracy: 0.9870\n",
      "Epoch [6/10] | Loss: 0.0417 | Accuracy: 0.9843\n",
      "Epoch [7/10] | Loss: 0.0236 | Accuracy: 0.9929\n",
      "Epoch [8/10] | Loss: 0.0115 | Accuracy: 0.9964\n",
      "Epoch [9/10] | Loss: 0.0203 | Accuracy: 0.9921\n",
      "Epoch [10/10] | Loss: 0.0215 | Accuracy: 0.9919\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "model=Resnet34()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "criterion=nn.BCEWithLogitsLoss()\n",
    "optimizer=optim.Adam(model.parameters(),lr=1e-4)\n",
    "\n",
    "num_epochs=10\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    runningloss=0\n",
    "    correct=0\n",
    "    total=0\n",
    "\n",
    "    for inputs, targets in train_loader:\n",
    "        inputs=inputs.to(device)\n",
    "        targets=targets.to(device).float().unsqueeze(1)\n",
    "        outputs=model(inputs)\n",
    "        loss=criterion(outputs,targets)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        runningloss+=loss.item()\n",
    "\n",
    "        pred=torch.sigmoid(outputs)>0.5\n",
    "        correct+=(pred==targets.bool()).sum().item()\n",
    "        total+=targets.size(0)\n",
    "    epoch_loss=runningloss/len(train_loader)\n",
    "    epoch_acc=correct/total\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}] | Loss: {epoch_loss:.4f} | Accuracy: {epoch_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed91ad6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_layer_structure(model, indent=0):\n",
    "    for name, layer in model.named_children():\n",
    "        print(\"  \" * indent + f\"{name}: {layer.__class__.__name__}\")\n",
    "        print_layer_structure(layer, indent + 1)\n",
    "\n",
    "model = ResNet34(num_classes=1)\n",
    "print_layer_structure(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed1d424b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 17810,
     "sourceId": 23812,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 921.801893,
   "end_time": "2025-04-07T11:16:35.441856",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-04-07T11:01:13.639963",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
